{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3106933-22c4-4240-a01a-51ca901bcfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "def execute_sql_code_from_string(input_string):\n",
    "    \n",
    "    sql_blocks = re.findall(r'```sql\\s*(.*?)\\s*```', input_string, re.DOTALL | re.IGNORECASE)\n",
    "    \n",
    "    if not sql_blocks:\n",
    "        return [False, \"No SQL block found.\"]\n",
    "    \n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=\"synthea\",\n",
    "            user=\"admin\",\n",
    "            password=\"adminpassword\",\n",
    "            host=\"localhost\",\n",
    "            port=\"5432\"\n",
    "        )\n",
    "        conn.autocommit = True\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        for sql_code in sql_blocks:\n",
    "            print(f\"Executing SQL:\\n{sql_code}\\n---\")\n",
    "            cursor.execute(sql_code)\n",
    "            if cursor.description:\n",
    "                # Get column names\n",
    "                colnames = [desc[0] for desc in cursor.description]\n",
    "                # Fetch all data\n",
    "                rows = cursor.fetchall()\n",
    "                # Convert to DataFrame\n",
    "                df = pd.DataFrame(rows, columns=colnames)\n",
    "                return [True, df]\n",
    "        \n",
    "        return [True, None]\n",
    "        \n",
    "    except psycopg2.Error as e:\n",
    "        error_msg = f\"SQL Execution Error: {e}\"\n",
    "        print(error_msg)\n",
    "        return [False, error_msg]\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Unexpected Error: {e}\"\n",
    "        print(error_msg)\n",
    "        return [False, error_msg]\n",
    "    finally:\n",
    "        if 'cursor' in locals():\n",
    "            cursor.close()\n",
    "        if 'conn' in locals():\n",
    "            conn.close()\n",
    "            \n",
    "def groq_chat_completion_stream_clean(prompt, model=\"llama3-8b-8192\"):\n",
    "    GROQ_API_KEY = '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'\n",
    "    if not GROQ_API_KEY:\n",
    "        raise ValueError(\"La clé API Groq n'est pas configurée dans le fichier .env\")\n",
    "    \n",
    "    url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {GROQ_API_KEY}\"\n",
    "    }\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"stream\": True  \n",
    "    }\n",
    "    response_text = \"\"\n",
    "    with requests.post(url, headers=headers, json=data, stream=True) as response:\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"Erreur API: {response.status_code} - {response.text}\")\n",
    "        \n",
    "        for chunk in response.iter_lines():\n",
    "            if chunk:\n",
    "                decoded_chunk = chunk.decode('utf-8')\n",
    "                if decoded_chunk.startswith(\"data:\"):\n",
    "                    try:\n",
    "                        parsed = json.loads(decoded_chunk[5:].strip())\n",
    "                        content = parsed.get(\"choices\", [{}])[0].get(\"delta\", {}).get(\"content\")\n",
    "                        if content:\n",
    "                            response_text += content\n",
    "                    except json.JSONDecodeError:\n",
    "                        continue  \n",
    "\n",
    "    return response_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd1760e-b7e1-4053-9136-9e892ce5d112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder = \"/json/location/\"\n",
    "conversation_history = [] \n",
    "\n",
    "for file_name in os.listdir(folder):\n",
    "    path = os.path.join(folder, file_name)\n",
    "    if os.path.isfile(path):\n",
    "        json_format = pd.read_json(path)\n",
    "        json_str = json_format.to_json(orient=\"records\", indent=2)\n",
    "        \n",
    "        context = \"\\n\\n\".join(conversation_history) if conversation_history else \"\"\n",
    "        final_prompt = prompt + \"\\n\\n\" + json_str\n",
    "        if context:\n",
    "            final_prompt = context + \"\\n\\n\" + final_prompt\n",
    "        \n",
    "        llm_response = groq_chat_completion_stream_clean(final_prompt)\n",
    "        \n",
    "        conversation_history.append(f\"User: Processing file {file_name}\")\n",
    "        conversation_history.append(f\"Data: {json_str}\")\n",
    "        conversation_history.append(f\"Assistant: {llm_response}\")\n",
    "        \n",
    "        sql_output = execute_sql_code_from_string(llm_response)\n",
    "        \n",
    "        if sql_output[0]: \n",
    "\n",
    "            tool_response = 'Code successfully executed' + \"\\n\\n\" + str(sql_output[1])\n",
    "            \n",
    "            context_with_success = \"\\n\\n\".join(conversation_history) + \"\\n\\n\" + tool_response\n",
    "            final_result = groq_chat_completion_stream_clean(context_with_success)\n",
    "            \n",
    "            conversation_history.append(f\"System: {tool_response}\")\n",
    "            conversation_history.append(f\"Assistant: {final_result}\")\n",
    "            \n",
    "            print(f\"✅ Successfully processed {file_name}\")\n",
    "            print(f\"Final result: {final_result}\")\n",
    "            \n",
    "        else:\n",
    "            error_response = f'Code execution failed: {sql_output[1]}'\n",
    "            \n",
    "            context_with_error = \"\\n\\n\".join(conversation_history) + \"\\n\\n\" + error_response\n",
    "            error_result = groq_chat_completion_stream_clean(context_with_error)\n",
    "            \n",
    "            conversation_history.append(f\"System: {error_response}\")\n",
    "            conversation_history.append(f\"Assistant: {error_result}\")\n",
    "            \n",
    "            print(f\"❌ Failed to process {file_name}\")\n",
    "            print(f\"Error: {sql_output[1]}\")\n",
    "            print(f\"LLM error response: {error_result}\")\n",
    "        \n",
    "        print(\"-\" * 50)  \n",
    "\n",
    "print(f\"\\nProcessed {len([f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))])} files\")\n",
    "print(f\"Total conversation history entries: {len(conversation_history)}\")\n",
    "\n",
    "with open(\"conversation_history.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\\n\".join(conversation_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b48c57-6ecd-473e-bf68-4c365c40983d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1ca6776-d013-4baf-9742-184c83d3a147",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the generated SQL code:\n",
      "\n",
      "```\n",
      "INSERT INTO omop.location (\n",
      "    city,\n",
      "    state,\n",
      "    zip,\n",
      "    location_source_value,\n",
      "    address_1,\n",
      "    address_2,\n",
      "    county\n",
      ")\n",
      "SELECT \n",
      "    l.city,\n",
      "    l.state_abbreviation AS state,\n",
      "    l.zip,\n",
      "    l.zip AS location_source_value,\n",
      "    NULL AS address_1, -- since column-level transformation rule is to null\n",
      "    NULL AS address_2, -- since column-level transformation rule is to null\n",
      "    NULL AS county   -- since column-level transformation rule is to null\n",
      "FROM \n",
      "    location_enriched_view AS l;\n",
      "```\n",
      "\n",
      "Note: I've included inline comments to clarify the logic of column-level transformation rules that result in `NULL` values. I've also assumed that the `cast_type` values for `address_1`, `address_2`, and `county` are not necessary since they don't seem to have a specific transformation rule. If there's an error in the execution, I'd be happy to review and correct!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "with open(\"prompt/prompt1.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    prompt = f.read()\n",
    "\n",
    "try:\n",
    "\n",
    "    with open(\"json/location/location_test_1.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        json_data = json.load(f)\n",
    "    json_str = json.dumps(json_data, indent=2)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"JSON file not found. Please check the file path.\")\n",
    "    json_str = \"{}\"\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Invalid JSON format: {e}\")\n",
    "    json_str = \"{}\"\n",
    "\n",
    "final_prompt = prompt + \"\\n\\n\" + json_str\n",
    "result = groq_chat_completion_stream_clean(final_prompt)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04ee806-e07a-4db8-9c26-b1984501571a",
   "metadata": {},
   "source": [
    "Here is the generated SQL code:\n",
    "\n",
    "```\n",
    "CREATE OR REPLACE VIEW omop.location_enriched_view AS \n",
    "SELECT \n",
    "  s.city, \n",
    "  s.state, \n",
    "  s.zip, \n",
    "  sm.state_abbreviation\n",
    "FROM \n",
    "  synthea.patients s \n",
    "  LEFT JOIN omop.states_map ON s.state = sm.state;\n",
    "```\n",
    "```\n",
    "INSERT INTO omop.location (\n",
    "  location_id,\n",
    "  city,\n",
    "  state,\n",
    "  zip,\n",
    "  location_source_value,\n",
    "  address_1,\n",
    "  address_2,\n",
    "  county\n",
    ")\n",
    "SELECT \n",
    "  MD5HASH(city || state_abbreviation || zip)::uuid AS location_id,\n",
    "  city,\n",
    "  state_abbreviation AS state,\n",
    "  zip,\n",
    "  zip AS location_source_value,\n",
    "  NULL::VARCHAR AS address_1,\n",
    "  NULL::VARCHAR AS address_2,\n",
    "  NULL::VARCHAR AS county\n",
    "FROM \n",
    "  location_enriched_view;\n",
    "```\n",
    "Let me know if this generates any execution errors!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e721ce7-3259-4931-a394-35c2e09d7ea0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
