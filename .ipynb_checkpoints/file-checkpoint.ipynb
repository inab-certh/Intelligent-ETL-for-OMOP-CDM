{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1ca6776-d013-4baf-9742-184c83d3a147",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "-- Create the target table with the required structure\n",
      "CREATE TABLE clients (\n",
      "    client_id INT,\n",
      "    last_name VARCHAR(255),\n",
      "    first_name VARCHAR(255),\n",
      "    birth_date DATE,\n",
      "    postal_code VARCHAR(10),\n",
      "    email VARCHAR(255)\n",
      ");\n",
      "\n",
      "-- Create a view to handle complex transformations\n",
      "CREATE VIEW clients_source_view AS\n",
      "SELECT \n",
      "    ID_CLIENT,\n",
      "    NOM_PRENOM,\n",
      "    DATE_NAISSANCE,\n",
      "    ADRESSE_COMPLETE,\n",
      "    EMAIL\n",
      "FROM CLIENTS_SOURCE;\n",
      "\n",
      "-- Insert into target table with transformations\n",
      "INSERT INTO clients (\n",
      "    client_id,\n",
      "    last_name,\n",
      "    first_name,\n",
      "    birth_date,\n",
      "    postal_code,\n",
      "    email\n",
      ")\n",
      "SELECT \n",
      "    CSV.ID_CLIENT AS client_id,\n",
      "    -- Split NOM_PRENOM to extract last name\n",
      "    SPLIT_PART(CSV.NOM_PRENOM, ' ', 1) AS last_name,\n",
      "    -- Split NOM_PRENOM to extract first name (handle multiple delimiters)\n",
      "    CASE \n",
      "        WHEN POSITION('_', CSV.NOM_PRENOM) > 0 THEN SPLIT_PART(REPLACE(CSV.NOM_PRENOM, '_', ' '), ' ', 2)\n",
      "        WHEN POSITION('-', CSV.NOM_PRENOM) > 0 THEN SPLIT_PART(REPLACE(CSV.NOM_PRENOM, '-', ' '), ' ', 2)\n",
      "        ELSE SPLIT_PART(CSV.NOM_PRENOM, ' ', 2)\n",
      "    END AS first_name,\n",
      "    -- Convert date to ISO format\n",
      "    TO_DATE(CSV.DATE_NAISSANCE, 'DD/MM/YYYY') AS birth_date,\n",
      "    -- Extract postal code using regex\n",
      "    REGEXP_SUBSTR(CSV.ADRESSE_COMPLETE, '\\b(\\d{5})\\b', 1, 1, NULL, 1) AS postal_code,\n",
      "    -- Convert email to lowercase\n",
      "    LOWER(CSV.EMAIL) AS email\n",
      "FROM clients_source_view CSV;\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import psycopg2\n",
    "\n",
    "def execute_sql_code_from_string(input_string):\n",
    "    sql_blocks = re.findall(r'```sql\\s*(.*?)\\s*```', input_string, re.DOTALL | re.IGNORECASE)\n",
    "    \n",
    "    if not sql_blocks:\n",
    "        print(\"Aucun bloc SQL trouvé.\")\n",
    "        return\n",
    "    \n",
    "    # Connexion à PostgreSQL\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=\"postgres\",\n",
    "            user=\"admin\",\n",
    "            password=\"adminpassword\",\n",
    "            host=\"localhost\",\n",
    "            port=\"5432\"\n",
    "        )\n",
    "        conn.autocommit = True\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        for sql_code in sql_blocks:\n",
    "            print(f\"Exécution du SQL :\\n{sql_code}\\n---\")\n",
    "            cursor.execute(sql_code)\n",
    "        \n",
    "        print(\"Exécution terminée avec succès.\")\n",
    "\n",
    "    except psycopg2.Error as e:\n",
    "        print(f\"Erreur lors de la connexion ou exécution SQL : {e}\")\n",
    "    \n",
    "    finally:\n",
    "        if 'cursor' in locals():\n",
    "            cursor.close()\n",
    "        if 'conn' in locals():\n",
    "            conn.close()\n",
    "            \n",
    "def groq_chat_completion_stream_clean(prompt, model=\"llama3-70b-8192\"):\n",
    "    GROQ_API_KEY = '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'\n",
    "    if not GROQ_API_KEY:\n",
    "        raise ValueError(\"La clé API Groq n'est pas configurée dans le fichier .env\")\n",
    "    \n",
    "    url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {GROQ_API_KEY}\"\n",
    "    }\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"stream\": True  \n",
    "    }\n",
    "    response_text = \"\"\n",
    "    with requests.post(url, headers=headers, json=data, stream=True) as response:\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"Erreur API: {response.status_code} - {response.text}\")\n",
    "        \n",
    "        for chunk in response.iter_lines():\n",
    "            if chunk:\n",
    "                decoded_chunk = chunk.decode('utf-8')\n",
    "                if decoded_chunk.startswith(\"data:\"):\n",
    "                    try:\n",
    "                        parsed = json.loads(decoded_chunk[5:].strip())\n",
    "                        content = parsed.get(\"choices\", [{}])[0].get(\"delta\", {}).get(\"content\")\n",
    "                        if content:\n",
    "                            response_text += content\n",
    "                    except json.JSONDecodeError:\n",
    "                        continue  \n",
    "\n",
    "    return response_text.strip()\n",
    "\n",
    "\n",
    "prompt = \"\"\"\n",
    "SYSTEM PROMPT :\n",
    "\n",
    "You are a highly capable AI specialized in generating optimized SQL code.\n",
    "\n",
    "## Objective:\n",
    "\tYour task is to generate SQL code that transforms data from a **source database (A)** to a **target database (B)**.\n",
    "\tYou will receive, for each step, a JSON that describes the transformation needed for **one specific target table only**, including:\n",
    "\t  - The structure of the source table(s) involved (columns, data types).\n",
    "\t  - The details of the transformation for each target column (\"transformation_type\" and \"description\").\n",
    "\n",
    "## Important constraints:\n",
    "\t- The migration will be handled **table by table**, not globally.\n",
    "\t- You must focus **only on the target table provided in the JSON**, ignoring any other tables until explicitly given.\n",
    "\t- Do not attempt to infer transformations for other target tables.\n",
    "\n",
    "## Instructions:\n",
    "\t- Carefully analyze the JSON to fully understand the data model and the transformation rules for the target table.\n",
    "\t- Generate clean, well-structured, and **highly optimized SQL code** that performs the described transformation **only for the specified target table**.\n",
    "\n",
    "## Best practices to strictly follow.\n",
    "To ensure the SQL code is efficient, readable, and maintainable, please follow these best practices:\n",
    "\t- Prioritize code efficiency and readability.\n",
    "\t- Use **views** for complex queries to improve modularity.\n",
    "\t- Use **stored procedures** if tasks are repetitive or part of a workflow.\n",
    "\t- Prefer **JOINs** over subqueries whenever possible.\n",
    "\t- Always **limit selected columns** explicitly (never use `SELECT *`).\n",
    "\t- Apply **indexing strategies** where relevant to improve performance.\n",
    "\t- Comment your SQL code where necessary to explain complex logic.\n",
    "\n",
    "## Output:\n",
    "\t- Provide only the SQL code that builds the **target table transformation as described in the JSON**.\n",
    "\t- Include inline comments if needed to clarify complex operations.\n",
    "\t- Do not generate explanations or verbal outputs SQL code only.\n",
    "\t\n",
    "## Errors Handling :\n",
    "\n",
    "Your code will be tested in real time after you give the output. If there are any errors, they will be sent to you through the IPython role\n",
    "\n",
    "USER INPUT \n",
    "\n",
    "{\n",
    "\"target_table\": \"clients\",\n",
    "\"source_table_involve\": \"CLIENTS_SOURCE\",\n",
    "\"columns\": [\n",
    "{\n",
    "\"target_column\": \"client_id\",\n",
    "\"source_column\": \"ID_CLIENT\",\n",
    "\"transformation_type\": \"direct_copy\",\n",
    "\"description\": \"Client ID kept as is.\"\n",
    "},\n",
    "{\n",
    "\"target_column\": \"last_name\",\n",
    "\"source_column\": \"NOM_PRENOM\",\n",
    "\"transformation_type\": \"split_string\",\n",
    "\"delimiter\": [\" \", \"_\" , \"-\" ],\n",
    "\"part_index\": 0,\n",
    "\"description\": \"Extracting the last name from the composite field NOM_PRENOM.\"\n",
    "},\n",
    "{\n",
    "\"target_column\": \"first_name\",\n",
    "\"source_column\": \"NOM_PRENOM\",\n",
    "\"transformation_type\": \"split_string\",\n",
    "\"delimiter\": \" \",\n",
    "\"part_index\": 1,\n",
    "\"description\": \"Extracting the first name from the composite field NOM_PRENOM.\"\n",
    "},\n",
    "{\n",
    "\"target_column\": \"birth_date\",\n",
    "\"source_column\": \"DATE_NAISSANCE\",\n",
    "\"transformation_type\": \"date_format\",\n",
    "\"source_format\": \n",
    "\"target_format\": \"YYYY-MM-DD\",\n",
    "\"description\": \"Converting the date to ISO format. source format DD/MM/YYYY tqr\"\n",
    "},\n",
    "{\n",
    "\"target_column\": \"postal_code\",\n",
    "\"source_column\": \"ADRESSE_COMPLETE\",\n",
    "\"transformation_type\": \"regex_extract\",\n",
    "\"description\": \"Extracting the postal code using a regex using this pattern \"\\\\b(\\\\d{5})\\\\b\" \"\n",
    "},\n",
    "{\n",
    "\"target_column\": \"email\",\n",
    "\"source_column\": \"EMAIL\",\n",
    "\"transformation_type\": \"lowercase\",\n",
    "\"description\": \"Converting the email to lowercase.\"\n",
    "}\n",
    "]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "result = groq_chat_completion_stream_clean(prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15867f8-2716-41a3-a42b-ef937b00e6a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5a58f4-e569-4603-91cd-306a8bfabbd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2417c807-2c12-4827-898d-b538a2308cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdda4814-dae8-4345-ac40-e7b76a61ba29",
   "metadata": {},
   "source": [
    "llama3.1\n",
    "\n",
    "Here is the optimized SQL code that transforms the data from the source database to the target database for the target table \"clients\":\n",
    "\n",
    "```sql\n",
    "CREATE OR REPLACE VIEW clients_view AS\n",
    "SELECT \n",
    "    c.ID_CLIENT AS client_id,\n",
    "    SPLIT(NOM_PRENOM, ' ', 1) AS first_name,\n",
    "    SPLIT(NOM_PRENOM, ' ', 2) AS last_name,\n",
    "    TO_DATE(SUBSTRING(DATE_NAISSANCE FROM '^\\d{2}/\\d{2}/\\d{4}$'), 'DD/MM/YYYY') AS birth_date,\n",
    "    REGEXP_EXTRACT(ADRESSE_COMPLETE, r'\\b(\\d{5})\\b') AS postal_code,\n",
    "    LOWER(EMAIL) AS email\n",
    "FROM \n",
    "    CLIENTS_SOURCE c;\n",
    "```\n",
    "\n",
    "This SQL code creates a view called `clients_view` that performs the described transformations for the target table \"clients\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da339512-d275-4c7b-8ec6-6e2066422703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa75bde8-a443-4708-b6d1-060483dd2aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = df[['ADDRESS', 'CITY', 'STATE', 'ZIP']].copy()\n",
    "\n",
    "state_map = df[['STATE', 'COUNTY']].copy()\n",
    "state_map.columns = ['STATE', 'STATE_ABBREVIATION'] \n",
    "\n",
    "state_map.to_csv(\"/home/petriscyril/Desktop/Agent_ETL/Synthea/state_map.csv\", index=False)\n",
    "location.to_csv(\"/home/petriscyril/Desktop/Agent_ETL/Synthea/location.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c19d57a-4bbb-428c-ab0f-980c8d013494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Id', 'BIRTHDATE', 'DEATHDATE', 'SSN', 'DRIVERS', 'PASSPORT', 'PREFIX', 'FIRST', 'MIDDLE', 'LAST', 'SUFFIX', 'MAIDEN', 'MARITAL', 'RACE', 'ETHNICITY', 'GENDER', 'BIRTHPLACE', 'ADDRESS', 'CITY', 'STATE', 'COUNTY', 'FIPS', 'ZIP', 'LAT', 'LON', 'HEALTHCARE_EXPENSES', 'HEALTHCARE_COVERAGE', 'INCOME']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78f53eef-f9fa-4d0e-ba64-bc20833f891e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADDRESS</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>MAIDEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>964 Johnson Throughway</td>\n",
       "      <td>GIRALDO</td>\n",
       "      <td>ANTIOQUIA</td>\n",
       "      <td>5306</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1041 Deckow Viaduct Suite 7</td>\n",
       "      <td>BETANIA</td>\n",
       "      <td>ANTIOQUIA</td>\n",
       "      <td>5091</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>641 Orn Trafficway Unit 91</td>\n",
       "      <td>SABANETA</td>\n",
       "      <td>ANTIOQUIA</td>\n",
       "      <td>5631</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>324 Cronin Street</td>\n",
       "      <td>LA ESTRELLA</td>\n",
       "      <td>ANTIOQUIA</td>\n",
       "      <td>5380</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>380 Kuhn Key Unit 52</td>\n",
       "      <td>MEDELLIN</td>\n",
       "      <td>ANTIOQUIA</td>\n",
       "      <td>5001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10632</th>\n",
       "      <td>207 Olson Gate</td>\n",
       "      <td>TUNJA</td>\n",
       "      <td>BOYACA</td>\n",
       "      <td>15001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10633</th>\n",
       "      <td>563 Ortiz Trace</td>\n",
       "      <td>PAUNA</td>\n",
       "      <td>BOYACA</td>\n",
       "      <td>15531</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10634</th>\n",
       "      <td>393 Shields Route</td>\n",
       "      <td>SAMACA</td>\n",
       "      <td>BOYACA</td>\n",
       "      <td>15646</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10635</th>\n",
       "      <td>824 Gulgowski Hollow</td>\n",
       "      <td>DUITAMA</td>\n",
       "      <td>BOYACA</td>\n",
       "      <td>15238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10636</th>\n",
       "      <td>719 Mueller Extension Apt 59</td>\n",
       "      <td>RAMIRIQUI</td>\n",
       "      <td>BOYACA</td>\n",
       "      <td>15599</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10637 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ADDRESS         CITY      STATE    ZIP MAIDEN\n",
       "0            964 Johnson Throughway      GIRALDO  ANTIOQUIA   5306    NaN\n",
       "1       1041 Deckow Viaduct Suite 7      BETANIA  ANTIOQUIA   5091    NaN\n",
       "2        641 Orn Trafficway Unit 91     SABANETA  ANTIOQUIA   5631    NaN\n",
       "3                 324 Cronin Street  LA ESTRELLA  ANTIOQUIA   5380    NaN\n",
       "4              380 Kuhn Key Unit 52     MEDELLIN  ANTIOQUIA   5001    NaN\n",
       "...                             ...          ...        ...    ...    ...\n",
       "10632                207 Olson Gate        TUNJA     BOYACA  15001    NaN\n",
       "10633               563 Ortiz Trace        PAUNA     BOYACA  15531    NaN\n",
       "10634             393 Shields Route       SAMACA     BOYACA  15646    NaN\n",
       "10635          824 Gulgowski Hollow      DUITAMA     BOYACA  15238    NaN\n",
       "10636  719 Mueller Extension Apt 59    RAMIRIQUI     BOYACA  15599    NaN\n",
       "\n",
       "[10637 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['ADDRESS','CITY','STATE','ZIP','MAIDEN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232c517d-b24a-417a-83e4-daef851adfae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
