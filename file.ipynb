{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3106933-22c4-4240-a01a-51ca901bcfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "def execute_sql_code_from_string(input_string):\n",
    "    sql_blocks = re.findall(r'```sql\\s*(.*?)\\s*```', input_string, re.DOTALL | re.IGNORECASE)\n",
    "    \n",
    "    if not sql_blocks:\n",
    "        print(\"No SQL block found.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=\"synthea\",\n",
    "            user=\"admin\",\n",
    "            password=\"adminpassword\",\n",
    "            host=\"localhost\",\n",
    "            port=\"5432\"\n",
    "        )\n",
    "        conn.autocommit = True\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        for sql_code in sql_blocks:\n",
    "            print(f\"Executing SQL:\\n{sql_code}\\n---\")\n",
    "            cursor.execute(sql_code)\n",
    "\n",
    "            if cursor.description:\n",
    "                # Get column names\n",
    "                colnames = [desc[0] for desc in cursor.description]\n",
    "                # Fetch all data\n",
    "                rows = cursor.fetchall()\n",
    "                # Convert to DataFrame\n",
    "                df = pd.DataFrame(rows, columns=colnames)\n",
    "                return df\n",
    "\n",
    "        return None  \n",
    "\n",
    "    except psycopg2.Error as e:\n",
    "        print(f\"SQL Execution Error: {e}\")\n",
    "        return None\n",
    "\n",
    "    finally:\n",
    "        if 'cursor' in locals():\n",
    "            cursor.close()\n",
    "        if 'conn' in locals():\n",
    "            conn.close()\n",
    "            \n",
    "def groq_chat_completion_stream_clean(prompt, model=\"llama3-70b-8192\"):\n",
    "    GROQ_API_KEY = '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'\n",
    "    if not GROQ_API_KEY:\n",
    "        raise ValueError(\"La clé API Groq n'est pas configurée dans le fichier .env\")\n",
    "    \n",
    "    url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {GROQ_API_KEY}\"\n",
    "    }\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"stream\": True  \n",
    "    }\n",
    "    response_text = \"\"\n",
    "    with requests.post(url, headers=headers, json=data, stream=True) as response:\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"Erreur API: {response.status_code} - {response.text}\")\n",
    "        \n",
    "        for chunk in response.iter_lines():\n",
    "            if chunk:\n",
    "                decoded_chunk = chunk.decode('utf-8')\n",
    "                if decoded_chunk.startswith(\"data:\"):\n",
    "                    try:\n",
    "                        parsed = json.loads(decoded_chunk[5:].strip())\n",
    "                        content = parsed.get(\"choices\", [{}])[0].get(\"delta\", {}).get(\"content\")\n",
    "                        if content:\n",
    "                            response_text += content\n",
    "                    except json.JSONDecodeError:\n",
    "                        continue  \n",
    "\n",
    "    return response_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1ca6776-d013-4baf-9742-184c83d3a147",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "-- Create the target table with the required structure\n",
      "CREATE TABLE clients (\n",
      "    client_id INT,\n",
      "    last_name VARCHAR(255),\n",
      "    first_name VARCHAR(255),\n",
      "    birth_date DATE,\n",
      "    postal_code VARCHAR(10),\n",
      "    email VARCHAR(255)\n",
      ");\n",
      "\n",
      "-- Create a view to handle complex transformations\n",
      "CREATE VIEW clients_source_view AS\n",
      "SELECT \n",
      "    ID_CLIENT,\n",
      "    NOM_PRENOM,\n",
      "    DATE_NAISSANCE,\n",
      "    ADRESSE_COMPLETE,\n",
      "    EMAIL\n",
      "FROM CLIENTS_SOURCE;\n",
      "\n",
      "-- Insert into target table with transformations\n",
      "INSERT INTO clients (\n",
      "    client_id,\n",
      "    last_name,\n",
      "    first_name,\n",
      "    birth_date,\n",
      "    postal_code,\n",
      "    email\n",
      ")\n",
      "SELECT \n",
      "    CSV.ID_CLIENT AS client_id,\n",
      "    -- Split NOM_PRENOM to extract last name\n",
      "    SPLIT_PART(CSV.NOM_PRENOM, ' ', 1) AS last_name,\n",
      "    -- Split NOM_PRENOM to extract first name (handle multiple delimiters)\n",
      "    CASE \n",
      "        WHEN POSITION('_', CSV.NOM_PRENOM) > 0 THEN SPLIT_PART(REPLACE(CSV.NOM_PRENOM, '_', ' '), ' ', 2)\n",
      "        WHEN POSITION('-', CSV.NOM_PRENOM) > 0 THEN SPLIT_PART(REPLACE(CSV.NOM_PRENOM, '-', ' '), ' ', 2)\n",
      "        ELSE SPLIT_PART(CSV.NOM_PRENOM, ' ', 2)\n",
      "    END AS first_name,\n",
      "    -- Convert date to ISO format\n",
      "    TO_DATE(CSV.DATE_NAISSANCE, 'DD/MM/YYYY') AS birth_date,\n",
      "    -- Extract postal code using regex\n",
      "    REGEXP_SUBSTR(CSV.ADRESSE_COMPLETE, '\\b(\\d{5})\\b', 1, 1, NULL, 1) AS postal_code,\n",
      "    -- Convert email to lowercase\n",
      "    LOWER(CSV.EMAIL) AS email\n",
      "FROM clients_source_view CSV;\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "SYSTEM PROMPT :\n",
    "\n",
    "You are a highly capable AI specialized in generating optimized SQL code.\n",
    "\n",
    "## Objective:\n",
    "\tYour task is to generate SQL code that transforms data from a **source database (A)** to a **target database (B)**.\n",
    "\tYou will receive, for each step, a JSON that describes the transformation needed for **one specific target table only**, including:\n",
    "\t  - The structure of the source table(s) involved (columns, data types).\n",
    "\t  - The details of the transformation for each target column (\"transformation_type\" and \"description\").\n",
    "\n",
    "## Important constraints:\n",
    "\t- The migration will be handled **table by table**, not globally.\n",
    "\t- You must focus **only on the target table provided in the JSON**, ignoring any other tables until explicitly given.\n",
    "\t- Do not attempt to infer transformations for other target tables.\n",
    "\n",
    "## Instructions:\n",
    "\t- Carefully analyze the JSON to fully understand the data model and the transformation rules for the target table.\n",
    "\t- Generate clean, well-structured, and **highly optimized SQL code** that performs the described transformation **only for the specified target table**.\n",
    "\n",
    "## Best practices to strictly follow.\n",
    "To ensure the SQL code is efficient, readable, and maintainable, please follow these best practices:\n",
    "\t- Prioritize code efficiency and readability.\n",
    "\t- Use **views** for complex queries to improve modularity.\n",
    "\t- Use **stored procedures** if tasks are repetitive or part of a workflow.\n",
    "\t- Prefer **JOINs** over subqueries whenever possible.\n",
    "\t- Always **limit selected columns** explicitly (never use `SELECT *`).\n",
    "\t- Apply **indexing strategies** where relevant to improve performance.\n",
    "\t- Comment your SQL code where necessary to explain complex logic.\n",
    "\n",
    "## Output:\n",
    "\t- Provide only the SQL code that builds the **target table transformation as described in the JSON**.\n",
    "\t- Include inline comments if needed to clarify complex operations.\n",
    "\t- Do not generate explanations or verbal outputs SQL code only.\n",
    "\t\n",
    "## Errors Handling :\n",
    "\n",
    "Your code will be tested in real time after you give the output. If there are any errors, they will be sent to you through the IPython role\n",
    "\n",
    "USER INPUT \n",
    "\n",
    "{\n",
    "\"target_table\": \"clients\",\n",
    "\"source_table_involve\": \"CLIENTS_SOURCE\",\n",
    "\"columns\": [\n",
    "{\n",
    "\"target_column\": \"client_id\",\n",
    "\"source_column\": \"ID_CLIENT\",\n",
    "\"transformation_type\": \"direct_copy\",\n",
    "\"description\": \"Client ID kept as is.\"\n",
    "},\n",
    "{\n",
    "\"target_column\": \"last_name\",\n",
    "\"source_column\": \"NOM_PRENOM\",\n",
    "\"transformation_type\": \"split_string\",\n",
    "\"delimiter\": [\" \", \"_\" , \"-\" ],\n",
    "\"part_index\": 0,\n",
    "\"description\": \"Extracting the last name from the composite field NOM_PRENOM.\"\n",
    "},\n",
    "{\n",
    "\"target_column\": \"first_name\",\n",
    "\"source_column\": \"NOM_PRENOM\",\n",
    "\"transformation_type\": \"split_string\",\n",
    "\"delimiter\": \" \",\n",
    "\"part_index\": 1,\n",
    "\"description\": \"Extracting the first name from the composite field NOM_PRENOM.\"\n",
    "},\n",
    "{\n",
    "\"target_column\": \"birth_date\",\n",
    "\"source_column\": \"DATE_NAISSANCE\",\n",
    "\"transformation_type\": \"date_format\",\n",
    "\"source_format\": \n",
    "\"target_format\": \"YYYY-MM-DD\",\n",
    "\"description\": \"Converting the date to ISO format. source format DD/MM/YYYY tqr\"\n",
    "},\n",
    "{\n",
    "\"target_column\": \"postal_code\",\n",
    "\"source_column\": \"ADRESSE_COMPLETE\",\n",
    "\"transformation_type\": \"regex_extract\",\n",
    "\"description\": \"Extracting the postal code using a regex using this pattern \"\\\\b(\\\\d{5})\\\\b\" \"\n",
    "},\n",
    "{\n",
    "\"target_column\": \"email\",\n",
    "\"source_column\": \"EMAIL\",\n",
    "\"transformation_type\": \"lowercase\",\n",
    "\"description\": \"Converting the email to lowercase.\"\n",
    "}\n",
    "]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "result = groq_chat_completion_stream_clean(prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b5a58f4-e569-4603-91cd-306a8bfabbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exécution du SQL :\n",
      "SELECT COUNT(*) FROM patients;\n",
      "---\n",
      "Exécution terminée avec succès.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "check_query = \"\"\"```sql\n",
    "SELECT COUNT(*) FROM patients;\n",
    "```\"\"\"\n",
    "print(execute_sql_code_from_string(check_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2417c807-2c12-4827-898d-b538a2308cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from datetime import datetime\n",
    "import pytest\n",
    "\n",
    "def test_table_person_structure(docker_db):\n",
    "    expected_columns = {\n",
    "        'person_id': 'integer',\n",
    "        'gender_concept_id': 'integer',\n",
    "        'year_of_birth': 'integer',\n",
    "        'month_of_birth': 'integer',\n",
    "        'day_of_birth': 'integer',\n",
    "        'birth_datetime': 'timestamp without time zone', \n",
    "        'race_concept_id': 'integer',\n",
    "        'ethnicity_concept_id': 'integer',\n",
    "        'location_id': 'integer',\n",
    "        'provider_id': 'integer',\n",
    "        'care_site_id': 'integer',\n",
    "        'person_source_value': 'character varying',  \n",
    "        'gender_source_value': 'character varying',\n",
    "        'gender_source_concept_id': 'integer',\n",
    "        'race_source_value': 'character varying',\n",
    "        'race_source_concept_id': 'integer',\n",
    "        'ethnicity_source_value': 'character varying',\n",
    "        'ethnicity_source_concept_id': 'integer'\n",
    "    }\n",
    "    \n",
    "    id_columns = [\n",
    "        'person_id',\n",
    "        'gender_concept_id',\n",
    "        'race_concept_id',\n",
    "        'ethnicity_concept_id',\n",
    "        'location_id',\n",
    "        'provider_id',\n",
    "        'care_site_id',\n",
    "        'gender_source_concept_id',\n",
    "        'race_source_concept_id',\n",
    "        'ethnicity_source_concept_id'\n",
    "    ]\n",
    "    \n",
    "    with psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        database=\"omop\",\n",
    "        user=\"admin\",\n",
    "        password=\"adminpassword\",\n",
    "        port=\"5432\"\n",
    "    ) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT column_name, data_type\n",
    "                FROM information_schema.columns\n",
    "                WHERE table_name = 'person'\n",
    "                AND table_schema = 'public';  -- replace with your schema if not 'public'\n",
    "            \"\"\")\n",
    "            \n",
    "            actual_columns = {row[0]: row[1] for row in cursor.fetchall()}\n",
    "            \n",
    "            missing_columns = set(expected_columns.keys()) - set(actual_columns.keys())\n",
    "            assert not missing_columns, f\"Missing columns: {missing_columns}\"\n",
    "            \n",
    "            type_mismatches = []\n",
    "            for column, expected_type in expected_columns.items():\n",
    "                if column in actual_columns and actual_columns[column] != expected_type:\n",
    "                    type_mismatches.append(\n",
    "                        f\"{column}: expected {expected_type}, got {actual_columns[column]}\"\n",
    "                    )\n",
    "            \n",
    "            assert not type_mismatches, \"Type mismatches:\\n\" + \"\\n\".join(type_mismatches)\n",
    "            \n",
    "            # Check for NULL values in ID columns\n",
    "            null_check_issues = []\n",
    "            for id_column in id_columns:\n",
    "                if id_column in actual_columns:\n",
    "                    cursor.execute(f\"\"\"\n",
    "                        SELECT COUNT(*) \n",
    "                        FROM person \n",
    "                        WHERE {id_column} IS NULL;\n",
    "                    \"\"\")\n",
    "                    null_count = cursor.fetchone()[0]\n",
    "                    \n",
    "                    if null_count > 0:\n",
    "                        null_check_issues.append(\n",
    "                            f\"{id_column} has {null_count} NULL values\"\n",
    "                        )\n",
    "            \n",
    "            assert not null_check_issues, \"NULL value issues in ID columns:\\n\" + \"\\n\".join(null_check_issues)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdda4814-dae8-4345-ac40-e7b76a61ba29",
   "metadata": {},
   "source": [
    "llama3.1\n",
    "\n",
    "Here is the optimized SQL code that transforms the data from the source database to the target database for the target table \"clients\":\n",
    "\n",
    "```sql\n",
    "CREATE OR REPLACE VIEW clients_view AS\n",
    "SELECT \n",
    "    c.ID_CLIENT AS client_id,\n",
    "    SPLIT(NOM_PRENOM, ' ', 1) AS first_name,\n",
    "    SPLIT(NOM_PRENOM, ' ', 2) AS last_name,\n",
    "    TO_DATE(SUBSTRING(DATE_NAISSANCE FROM '^\\d{2}/\\d{2}/\\d{4}$'), 'DD/MM/YYYY') AS birth_date,\n",
    "    REGEXP_EXTRACT(ADRESSE_COMPLETE, r'\\b(\\d{5})\\b') AS postal_code,\n",
    "    LOWER(EMAIL) AS email\n",
    "FROM \n",
    "    CLIENTS_SOURCE c;\n",
    "```\n",
    "\n",
    "This SQL code creates a view called `clients_view` that performs the described transformations for the target table \"clients\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "232c517d-b24a-417a-83e4-daef851adfae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>gender_concept_id</th>\n",
       "      <th>year_of_birth</th>\n",
       "      <th>month_of_birth</th>\n",
       "      <th>day_of_birth</th>\n",
       "      <th>birth_datetime</th>\n",
       "      <th>race_concept_id</th>\n",
       "      <th>ethnicity_concept_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>provider_id</th>\n",
       "      <th>care_site_id</th>\n",
       "      <th>person_source_value</th>\n",
       "      <th>gender_source_value</th>\n",
       "      <th>gender_source_concept_id</th>\n",
       "      <th>race_source_value</th>\n",
       "      <th>race_source_concept_id</th>\n",
       "      <th>ethnicity_source_value</th>\n",
       "      <th>ethnicity_source_concept_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8532</td>\n",
       "      <td>2005</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2005-07-06</td>\n",
       "      <td>0</td>\n",
       "      <td>38003563</td>\n",
       "      <td>314</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0002513e-8009-d8c4-9bf8-bdbb316deae8</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>native</td>\n",
       "      <td>0</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8532</td>\n",
       "      <td>2000</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>2000-10-18</td>\n",
       "      <td>8527</td>\n",
       "      <td>38003563</td>\n",
       "      <td>96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00035f01-cb9a-d253-eb67-7007a4e19ded</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8532</td>\n",
       "      <td>2001</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>2001-09-25</td>\n",
       "      <td>8527</td>\n",
       "      <td>38003563</td>\n",
       "      <td>103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>000b8952-a1f1-e576-834c-d55c9d7b0941</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8532</td>\n",
       "      <td>1989</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1989-10-01</td>\n",
       "      <td>8527</td>\n",
       "      <td>38003563</td>\n",
       "      <td>632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>001046c2-98bd-1b63-14c4-ab8f9a7ddfdc</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>8532</td>\n",
       "      <td>1992</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>1992-11-10</td>\n",
       "      <td>8527</td>\n",
       "      <td>38003563</td>\n",
       "      <td>456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0011424c-182d-59ac-5942-056a7f68d983</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_id  gender_concept_id  year_of_birth  month_of_birth  day_of_birth  \\\n",
       "0          1               8532           2005               7             6   \n",
       "1          2               8532           2000              10            18   \n",
       "2          3               8532           2001               9            25   \n",
       "3          4               8532           1989              10             1   \n",
       "4          5               8532           1992              11            10   \n",
       "\n",
       "  birth_datetime  race_concept_id  ethnicity_concept_id  location_id  \\\n",
       "0     2005-07-06                0              38003563          314   \n",
       "1     2000-10-18             8527              38003563           96   \n",
       "2     2001-09-25             8527              38003563          103   \n",
       "3     1989-10-01             8527              38003563          632   \n",
       "4     1992-11-10             8527              38003563          456   \n",
       "\n",
       "   provider_id  care_site_id                   person_source_value  \\\n",
       "0          NaN           NaN  0002513e-8009-d8c4-9bf8-bdbb316deae8   \n",
       "1          NaN           NaN  00035f01-cb9a-d253-eb67-7007a4e19ded   \n",
       "2          NaN           NaN  000b8952-a1f1-e576-834c-d55c9d7b0941   \n",
       "3          NaN           NaN  001046c2-98bd-1b63-14c4-ab8f9a7ddfdc   \n",
       "4          NaN           NaN  0011424c-182d-59ac-5942-056a7f68d983   \n",
       "\n",
       "  gender_source_value  gender_source_concept_id race_source_value  \\\n",
       "0                   F                         0            native   \n",
       "1                   F                         0             white   \n",
       "2                   F                         0             white   \n",
       "3                   F                         0             white   \n",
       "4                   F                         0             white   \n",
       "\n",
       "   race_source_concept_id ethnicity_source_value  ethnicity_source_concept_id  \n",
       "0                       0               hispanic                            0  \n",
       "1                       0               hispanic                            0  \n",
       "2                       0               hispanic                            0  \n",
       "3                       0               hispanic                            0  \n",
       "4                       0               hispanic                            0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person =  pd.read_csv('/home/petriscyril/Desktop/OMOP/OMOP_dataset/person.csv')\n",
    "person[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae71d582-2d60-44ea-8d89-f2d4c223f6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import modal\n",
    "\n",
    "MODEL_ID = \"NousResearch/Meta-Llama-3-8B\"\n",
    "MODEL_REVISION = \"315b20096dc791d381d514deb5f8bd9c8d6d3061\"\n",
    "\n",
    "image = modal.Image.debian_slim().pip_install(\n",
    "    \"transformers==4.49.0\", \"torch==2.6.0\", \"accelerate==1.4.0\"\n",
    ")\n",
    "app = modal.App(\"example-base-Meta-Llama-3-8B\", image=image)\n",
    "\n",
    "GPU_CONFIG = \"A100, 40 GB\"\n",
    "\n",
    "CACHE_DIR = \"/cache\"\n",
    "cache_vol = modal.Volume.from_name(\"hf-hub-cache\", create_if_missing=True)\n",
    "\n",
    "@app.cls(\n",
    "    gpu=GPU_CONFIG,\n",
    "    volumes={CACHE_DIR: cache_vol},\n",
    "    scaledown_window=10,\n",
    "    timeout=60,\n",
    ")\n",
    "@modal.concurrent(max_inputs=15)\n",
    "class Model:\n",
    "    @modal.enter()\n",
    "    def setup(self):\n",
    "        import torch\n",
    "        from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "        from huggingface_hub import snapshot_download\n",
    "\n",
    "        model_path = snapshot_download(repo_id=MODEL_ID, cache_dir=CACHE_DIR)\n",
    "\n",
    "        print(f\"Model downloaded to: {model_path}\")\n",
    "        model = AutoModelForCausalLM.from_pretrained(MODEL_ID, cache_dir=CACHE_DIR)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, cache_dir=CACHE_DIR)\n",
    "\n",
    "        self.pipeline = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "            device_map=\"auto\",\n",
    "        )\n",
    "\n",
    "    @modal.method()\n",
    "    def generate(self, input: str):\n",
    "        return self.pipeline(input)\n",
    "\n",
    "@app.local_entrypoint()\n",
    "def main(prompt: str = None):\n",
    "    if prompt is None:\n",
    "        prompt = \"Please write a Python function to compute the Fibonacci numbers.\"\n",
    "    print(Model().generate.remote(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2925bffe-39ac-42d3-860f-f1b6b327a37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[31mWas not able to launch web browser\u001b[0mthe web browser\n",
      "Please go to this URL manually and complete the flow:\n",
      "\n",
      "\u001b[2K\u001b]8;id=641599;https://modal.com/token-flow/tf-mBh8gSwTqLYJ6799dtHE4m\u001b\\\u001b[4;94mhttps://modal.com/token-flow/tf-mBh8gSwTqLYJ6799dtHE4m\u001b[0m\u001b]8;;\u001b\\\n",
      "\n",
      "\u001b[2K\u001b[32m⠋\u001b[0m Waiting for authentication in the web browser\n",
      "\u001b[2K\u001b[32m⠙\u001b[0m Waiting for token flow to complete...omplete...\n",
      "\u001b[1A\u001b[2K\u001b[32mWeb authentication finished successfully!\u001b[0m\n",
      "\u001b[32mToken is connected to the \u001b[0m\u001b[35mpetriscyril9\u001b[0m\u001b[32m workspace.\u001b[0m\n",
      "Verifying token against \u001b[4;34mhttps://api.modal.com\u001b[0m\n",
      "\u001b[32mToken verified successfully!\u001b[0m\n",
      "\u001b[?25l\u001b[32m⠋\u001b[0m Storing token\n",
      "\u001b[1A\u001b[2K\u001b[32mToken written to \u001b[0m\u001b[35m/home/petriscyril/\u001b[0m\u001b[35m.modal.toml\u001b[0m\u001b[32m in profile \u001b[0m\u001b[35mpetriscyril9\u001b[0m\u001b[32m.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!modal token new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb5ec1a8-0441-42e1-8193-eb974e3f1a89",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthError",
     "evalue": "Token missing. Could not authenticate client. If you have token credentials, see modal.com/docs/reference/modal.config for setup help. If you are a new user, register an account at modal.com, then run `modal token new`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Appeler directement la méthode avec un prompt spécifique\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m result = \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mremote\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPlease write a Python function to compute the Fibonacci numbers.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/venv/lib/python3.13/site-packages/synchronicity/synchronizer.py:592\u001b[39m, in \u001b[36mSynchronizer._wrap_proxy_method.<locals>.proxy_method\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    590\u001b[39m instance = \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m[synchronizer_self._original_attr]\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m592\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m UserCodeException \u001b[38;5;28;01mas\u001b[39;00m uc_exc:\n\u001b[32m    594\u001b[39m     uc_exc.exc.__suppress_context__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/venv/lib/python3.13/site-packages/synchronicity/combined_types.py:29\u001b[39m, in \u001b[36mFunctionWithAio.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m UserCodeException \u001b[38;5;28;01mas\u001b[39;00m uc_exc:\n\u001b[32m     28\u001b[39m     uc_exc.exc.__suppress_context__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m uc_exc.exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/venv/lib/python3.13/site-packages/modal/_object.py:272\u001b[39m, in \u001b[36mlive_method.<locals>.wrapped\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    270\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(method)\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.hydrate()\n\u001b[32m    273\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/venv/lib/python3.13/site-packages/modal/_object.py:263\u001b[39m, in \u001b[36m_Object.hydrate\u001b[39m\u001b[34m(self, client)\u001b[39m\n\u001b[32m    261\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_is_hydrated()\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m     c = client \u001b[38;5;28;01mif\u001b[39;00m client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _Client.from_env()\n\u001b[32m    264\u001b[39m     resolver = Resolver(c)\n\u001b[32m    265\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m resolver.load(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/venv/lib/python3.13/site-packages/modal/client.py:217\u001b[39m, in \u001b[36m_Client.from_env\u001b[39m\u001b[34m(cls, _override_config)\u001b[39m\n\u001b[32m    215\u001b[39m     credentials = (token_id, token_secret)\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m AuthError(\n\u001b[32m    218\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mToken missing. Could not authenticate client.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    219\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m If you have token credentials, see modal.com/docs/reference/modal.config for setup help.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    220\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m If you are a new user, register an account at modal.com, then run `modal token new`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    221\u001b[39m     )\n\u001b[32m    223\u001b[39m server_url = c[\u001b[33m\"\u001b[39m\u001b[33mserver_url\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    224\u001b[39m client = _Client(server_url, client_type, credentials)\n",
      "\u001b[31mAuthError\u001b[39m: Token missing. Could not authenticate client. If you have token credentials, see modal.com/docs/reference/modal.config for setup help. If you are a new user, register an account at modal.com, then run `modal token new`."
     ]
    }
   ],
   "source": [
    "# Appeler directement la méthode avec un prompt spécifique\n",
    "result = Model().generate.remote(\"Please write a Python function to compute the Fibonacci numbers.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "11604a83-5bf8-4045-8fc0-f44748697c64",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_Client.__init__() missing 3 required positional arguments: 'server_url', 'client_type', and 'credentials'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodal\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _Client\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m client = \u001b[43m_Client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Vérifiez que le client est bien connecté\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(client.is_authenticated())\n",
      "\u001b[31mTypeError\u001b[39m: _Client.__init__() missing 3 required positional arguments: 'server_url', 'client_type', and 'credentials'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048d27c4-619e-40ef-95b3-e9730d10ba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Was not able to launch web browserthe web browser\n",
    "Please go to this URL manually and complete the flow:\n",
    "\n",
    "\u001b]8;id=641599;https://modal.com/token-flow/tf-mBh8gSwTqLYJ6799dtHE4m\u001b\\https://modal.com/token-flow/tf-mBh8gSwTqLYJ6799dtHE4m\u001b]8;;\u001b\\\n",
    "\n",
    "⠋ Waiting for authentication in the web browser\n",
    "⠧ Waiting for token flow to complete...omplete..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0ad7c8-e10e-4190-ae26-3432d8281c86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
